{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Text Classification\n",
    "In this notebook, you will first see a simple Naive Bayes (NB) classifier, which is trained on a tiny toy corpus to classify texts into categories of 'sports' and 'not sports'. Then you are asked to apply and adjust the NB classifier to perform sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy tiny corpus: sports and non-sports sentences\n",
    "sports = ['A great game', 'Very clean match','A clean but forgettable game']\n",
    "non_sports = ['The election was over','It was a close election']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'great', 'game', 'very', 'clean', 'match', 'a', 'clean', 'but', 'forgettable', 'game', 'the', 'election', 'was', 'over', 'it', 'was', 'a', 'close', 'election']\n",
      "14 ['was', 'it', 'great', 'but', 'very', 'clean', 'forgettable', 'election', 'match', 'over', 'game', 'a', 'the', 'close']\n",
      "sport token nums 11\n",
      "sport type nums 8\n",
      "non-sport token nums 9\n",
      "non-sport type nums 7\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "all_words = []\n",
    "sport_words = []\n",
    "non_sport_words = []\n",
    "for sent in sports:\n",
    "    sport_words += [ww.lower() for ww in sent.split()]\n",
    "for sent in non_sports:\n",
    "    non_sport_words += [ww.lower() for ww in sent.split()]\n",
    "\n",
    "all_words = sport_words + non_sport_words\n",
    "vocab = list(set(all_words))\n",
    "\n",
    "print(all_words)\n",
    "print(len(vocab), vocab)\n",
    "\n",
    "print('sport token nums', len(sport_words))\n",
    "print('sport type nums', len(set(sport_words)))\n",
    "print('non-sport token nums', len(non_sport_words))\n",
    "print('non-sport type nums', len(set(non_sport_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prior distribution\n",
    "prior_sport = len(sports)*1./(len(sports)+len(non_sports))\n",
    "prior_non_sport = len(non_sports)*1./(len(sports)+len(non_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# get the word frequencies, which will be later used to compute likelihood\n",
    "from nltk import FreqDist\n",
    "sport_fd = FreqDist(sport_words)\n",
    "non_sport_fd = FreqDist(non_sport_words)\n",
    "\n",
    "print(sport_fd['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12, 0.08, 0.04, 0.12]\n",
      "[0.08695652173913043, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216]\n",
      "-9.985131541576639 -11.848829683156653\n",
      "sport\n"
     ]
    }
   ],
   "source": [
    "# NB classifier\n",
    "import numpy as np\n",
    "def predict_class(words):\n",
    "    sport_likelihood = []\n",
    "    non_likelihood = []\n",
    "    for ww in words:\n",
    "        sport_likelihood.append((sport_fd[ww]+1.)/(len(sport_words)+len(vocab)))\n",
    "        non_likelihood.append((non_sport_fd[ww]+1.)/(len(non_sport_words)+len(vocab)))\n",
    "    print(sport_likelihood)\n",
    "    print(non_likelihood)\n",
    "    s_loglhd = np.sum([np.log(l) for l in sport_likelihood])\n",
    "    n_loglhd = np.sum([np.log(l) for l in non_likelihood])\n",
    "    print(s_loglhd, n_loglhd)\n",
    "    sprob = np.log(prior_sport)+s_loglhd\n",
    "    nprob = np.log(prior_non_sport)+n_loglhd\n",
    "    if sprob > nprob: return 'sport'\n",
    "    else: return 'non_sport'\n",
    "    \n",
    "print(predict_class('a very interesting game'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: NB-based Sentiment Analysis\n",
    "*Sentiment analysis* is probably the most commerical application of text classification. It takes a customer review and checks the overall sentiment of the review. Here we use the movie review corpus to train a NB-based sentiment analyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document num 2000\n",
      "labels: {'neg', 'pos'}\n",
      "['ugh', '.', 'that', 'about', 'sums', 'this', 'movie', 'up', '.', 'just', ',', 'ugh', '.', 'the', 'original', 'godzilla', 'movies', 'are', 'somewhat', 'of', 'a', 'cult', 'classic', ',', 'and', 'when', 'reviewing', 'the', 'previous', 'films', ',', 'each', 'film', 'had', 'a', 'certain', 'degree', 'of', 'intelligence', '.', 'and', 'that', 'was', 'the', 'reason', 'they', 'found', 'such', 'an', 'enviable', 'cult', 'following', ';', 'in', 'spite', 'of', 'bad', 'special', 'effects', ',', 'horrible', 'dubbing', ',', 'and', 'a', 'man', 'in', 'a', 'lizard', 'suit', ',', 'they', 'maintained', 'a', 'certain', 'degree', 'of', '.', '.', '.', 'how', 'to', 'put', 'this', '?', '.', '.', '.', 'dignity', '?', 'not', 'quite', 'the', 'word', 'i', \"'\", 'm', 'looking', 'for', '.', 'you', 'understand', ',', 'right', '?', 'and', 'in', '50', 'years', ',', 'godzilla', 'has', 'maintained', 'that', 'degree', 'of', \"'\", 'whatever', \"'\", '.', 'leave', 'it', 'to', 'america', 'to', 'screw', 'the', 'whole', 'thing', 'up', '.', '>', 'from', 'the', \"'\", 'geniuses', \"'\", 'that', 'brought', 'us', '\"', 'independece', 'day', '\"', ',', 'arguably', 'the', 'worst', 'sci', '-', 'fi', 'movie', 'of', 'all', 'time', ',', 'to', 'ruin', 'whatever', 'reputation', 'godzilla', 'had', '.', 'while', 'they', 'do', 'bring', 'us', 'eye', '-', 'popping', 'special', 'effects', 'that', 'will', 'amaze', 'you', ',', 'they', 'lost', 'what', 'was', 'at', 'the', 'center', 'of', 'all', 'the', 'original', 'godzilla', 'movies', '--', 'a', 'storyline', '.', 'summing', 'up', 'the', 'movie', 'is', 'simple', '.', 'heck', ',', 'i', 'can', 'do', 'it', 'in', 'one', 'sentence', ':', 'giant', 'lizard', 'attacks', 'a', 'giant', 'city', 'and', 'a', 'bunch', 'of', 'nobodies', 'stop', 'it', '.', 'simple', 'as', 'that', '.', 'matthew', 'broderick', 'stumbles', 'over', 'his', 'lines', ',', 'and', 'it', \"'\", 's', 'hard', 'to', 'picture', 'hank', 'azaria', 'in', 'any', 'role', 'besides', 'his', 'classic', 'dog', '-', 'walking', 'character', 'on', 'the', 'television', 'show', '\"', 'mad', 'about', 'you', '\"', '.', 'the', 'dialogue', 'seems', 'to', 'be', 'improvized', ',', 'almost', 'as', 'if', 'there', 'was', 'no', 'rehearsel', 'done', 'at', 'all', '.', 'i', 'can', 'see', 'the', 'scene', 'on', 'the', 'set', 'right', 'now', '.', '\"', 'all', 'right', '!', 'we', 'spent', 'all', 'of', 'this', 'money', 'making', 'big', 'special', 'effects', ',', 'and', 'we', \"'\", 've', 'gotta', 'get', 'this', 'movie', 'out', 'by', 'summer', 'or', 'it', \"'\", 's', 'going', 'to', 'bomb', 'in', 'our', 'faces', '.', 'so', ',', 'you', 'actors', 'just', 'say', 'what', 'ever', 'comes', 'to', 'the', 'top', 'of', 'your', 'head', ',', 'all', 'right', '?', 'make', 'up', 'something', ',', 'm', \"'\", 'kay', '?', 'good', '.', 'roll', 'film', '!', '!', '\"', 'the', 'special', 'effects', 'are', 'enough', 'to', 'keep', 'you', 'interested', 'through', 'one', 'viewing', ',', 'and', 'some', 'of', 'the', 'cinemtography', 'is', 'well', '-', 'done', '(', 'the', 'scene', 'with', 'the', 'black', 'umbrellas', 'comes', 'to', 'mind', ')', '.', 'still', ',', 'an', 'hour', 'into', 'it', ',', 'you', 'will', 'become', 'antsy', ',', 'wondering', 'how', 'long', 'they', 'can', 'drag', 'it', 'out', '.', 'and', 'drag', 'it', 'out', 'they', 'do', '!', '!', 'i', 'have', 'to', 'laugh', '.', 'the', 'slogan', 'for', 'the', 'film', 'is', ',', '\"', 'size', 'does', 'matter', '\"', '.', 'i', 'think', 'they', 'cut', 'this', 'too', 'short', '.', 'it', 'should', 'read', ',', '\"', 'size', 'does', 'matter', '.', 'acting', 'does', 'not', '.', '\"'] neg\n"
     ]
    }
   ],
   "source": [
    "# obtain the data\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('document num', len(documents))\n",
    "print('labels:', set([dd[1] for dd in documents]))\n",
    "print(documents[0][0], documents[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, dev-test and test\n",
    "\n",
    "train_data = documents[:1200]\n",
    "dev_data = documents[1200:1600]\n",
    "test_data = documents[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_corpus = [train_data[i][0] for i,v in enumerate(train_data) for j,k in enumerate(v) if k=='neg']\n",
    "pos_corpus = [train_data[i][0] for i,v in enumerate(train_data) for j,k in enumerate(v) if k=='pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_corpus = [v[0] for i,v in enumerate(train_data) if v[-1]=='pos']\n",
    "len(pos_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build the prior probability of pos and neg (based on train_data)\n",
    "prior_pos = len(pos_corpus)*1./(len(pos_corpus)+len(neg_corpus))\n",
    "prior_neg = len(neg_corpus)*1./(len(pos_corpus)+len(neg_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5008333333333334 0.49916666666666665\n"
     ]
    }
   ],
   "source": [
    "print(prior_pos, prior_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32362\n",
      "sport token nums 498108\n",
      "sport type nums 24308\n",
      "non-sport token nums 453816\n",
      "non-sport type nums 22919\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary based on train_data\n",
    "# you may investigate whether to remove stopwords and punctuations and \n",
    "# whether to apply lemmatization/stemming, and compare their performance on dev-test set \n",
    "\n",
    "all_words = []\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "for sent in pos_corpus:\n",
    "    pos_words += [ww.lower() for ww in sent]\n",
    "for sent in neg_corpus:\n",
    "    neg_words += [ww.lower() for ww in sent]\n",
    "\n",
    "all_words = pos_words + neg_words\n",
    "vocab = list(set(all_words))\n",
    "\n",
    "#print(all_words)\n",
    "#print(len(vocab), vocab)\n",
    "print(len(vocab))\n",
    "print('sport token nums', len(pos_words))\n",
    "print('sport type nums', len(set(pos_words)))\n",
    "print('non-sport token nums', len(neg_words))\n",
    "print('non-sport type nums', len(set(neg_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each class (pos and neg), maintain the frequency of each type, so as to compute likelihood\n",
    "from nltk import FreqDist\n",
    "pos_fd = FreqDist(pos_words)\n",
    "neg_fd = FreqDist(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(neg_fd['interested'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.825\n",
      "(array([0.82741117, 0.8226601 ]), array([0.81909548, 0.83084577]), array([0.82323232, 0.82673267]), array([199, 201]))\n"
     ]
    }
   ],
   "source": [
    "# build the class prediction function\n",
    "def predict_sentiment(words):\n",
    "    pos_likelihood = []\n",
    "    neg_likelihood = []\n",
    "    for ww in words:\n",
    "        pos_likelihood.append((pos_fd[ww]+1.)/(len(pos_words)+len(vocab)))\n",
    "        neg_likelihood.append((neg_fd[ww]+1.)/(len(neg_words)+len(vocab)))\n",
    "    #print(pos_likelihood)\n",
    "    #print(neg_likelihood)\n",
    "    s_loglhd = np.sum([np.log(l) for l in pos_likelihood])\n",
    "    n_loglhd = np.sum([np.log(l) for l in neg_likelihood])\n",
    "    #print(s_loglhd, n_loglhd)\n",
    "    sprob = np.log(prior_pos)+s_loglhd\n",
    "    nprob = np.log(prior_neg)+n_loglhd\n",
    "    if sprob > nprob: \n",
    "        return 'pos'\n",
    "    else: \n",
    "        return 'neg'\n",
    "    \n",
    "# evaluate your model's performance on the dev-test set\n",
    "dev_pred_labels = []\n",
    "dev_true_labels = [ll for (dd,ll) in dev_data]\n",
    "for tt,_ in dev_data:\n",
    "    dev_pred_labels.append(predict_sentiment(tt))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "print('acc', accuracy_score(dev_true_labels, dev_pred_labels))\n",
    "print(precision_recall_fscore_support(dev_true_labels, dev_pred_labels, average=None, labels=['pos', 'neg']))\n",
    "\n",
    "# develop different models (with and without stopwords/punctuations/stemming/lemmatization),\n",
    "# and select the best model by its performance on the dev-test set;\n",
    "# the selected best model will be applied to test data in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8075\n",
      "(array([0.82887701, 0.78873239]), array([0.775, 0.84 ]), array([0.80103359, 0.81355932]), array([200, 200]))\n"
     ]
    }
   ],
   "source": [
    "# test the performance of the best model on test set\n",
    "test_pred_labels = []\n",
    "test_true_labels = [ll for (dd,ll) in test_data]\n",
    "for tt,_ in test_data:\n",
    "    test_pred_labels.append(predict_sentiment(tt))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "print('acc', accuracy_score(test_true_labels, test_pred_labels))\n",
    "print(precision_recall_fscore_support(test_true_labels, test_pred_labels, average=None, labels=['pos', 'neg']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": ".venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
